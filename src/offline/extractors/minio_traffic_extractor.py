import os
import logging
import time
from typing import Generator, Tuple, Optional

import polars as pl
from dotenv import load_dotenv
import boto3
import ijson  # B·∫ÆT BU·ªòC: pip install ijson

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

load_dotenv()

class MinIoTrafficExtractor:
    def __init__(self, raw_data_path: str):
        self.raw_data_path = raw_data_path
        self.endpoint = os.getenv("MINIO_ENDPOINT_URL")
        self.access_key = os.getenv("MINIO_ACCESS_KEY")
        self.secret_key = os.getenv("MINIO_SECRET_KEY")
        self.default_bucket = os.getenv("MINIO_BUCKET_NAME")
        
        if not all([self.endpoint, self.access_key, self.secret_key]):
            raise ValueError("Missing MinIO credentials.")
            
        self._s3_client = boto3.client(
            "s3",
            endpoint_url=self.endpoint,
            aws_access_key_id=self.access_key,
            aws_secret_access_key=self.secret_key,
        )

    def _get_s3_stream(self, bucket: str, key: str):
        """L·∫•y lu·ªìng d·ªØ li·ªáu (stream) thay v√¨ t·∫£i c·∫£ file."""
        try:
            response = self._s3_client.get_object(Bucket=bucket, Key=key)
            return response["Body"]
        except Exception as e:
            logger.error(f"Failed to get object s3://{bucket}/{key}: {e}")
            raise

    def _parse_traffic_stream(self, stream) -> Generator[Tuple[int, int, int], None, None]:
        """
        D√πng ijson ƒë·ªÉ duy·ªát qua file JSON m√† kh√¥ng load v√†o RAM.
        C·∫•u tr√∫c: { "YYYY-MM-DD": { "sensor_id": { "filename": { "count": X, ... } } } }
        """
        try:
            # ijson.kvitems(stream, "") gi√∫p duy·ªát qua level cao nh·∫•t (Date)
            for date_str, sensors in ijson.kvitems(stream, ""):
                for sensor_id, files in sensors.items():
                    for filename, details in files.items():
                        ts = self._extract_timestamp_from_filename(filename)
                        if ts is not None:
                            # Yield tuple (nh·∫π h∆°n dict) ƒë·ªÉ ti·∫øt ki·ªám memory
                            yield (
                                ts,
                                int(sensor_id),
                                int(details.get("count", 0))
                            )
        except Exception as e:
            logger.error(f"Error parsing stream: {e}")
            raise

    def extract(self) -> pl.LazyFrame:
        # X·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n
        if self.raw_data_path.startswith("s3://"):
            parts = self.raw_data_path.replace("s3://", "").split("/", 1)
            bucket, key = parts[0], parts[1]
        elif self.default_bucket:
            bucket, key = self.default_bucket, self.raw_data_path
        else:
            raise ValueError("Invalid path configuration")

        logger.info(f"üöÄ Streaming data from {bucket}/{key}")

        # 1. L·∫•y Stream
        stream = self._get_s3_stream(bucket, key)

        # 2. T·∫°o Generator
        record_generator = self._parse_traffic_stream(stream)

        # 3. T·∫°o Polars DataFrame t·ª´ Generator
        # Schema t∆∞·ªùng minh gi√∫p Polars c·∫•p ph√°t b·ªô nh·ªõ hi·ªáu qu·∫£
        schema = {
            "timestamp": pl.Int64,
            "sensor_id": pl.Int64,
            "count": pl.Int64
        }

        data_list = list(record_generator)
        if not data_list:
            logger.warning("‚ö†Ô∏è Generator yielded no data! Check your JSON structure or File Path.")
        # from_records ti√™u th·ª• generator tr·ª±c ti·∫øp
        df = pl.from_records(data_list, schema=schema, orient="row")
        
        logger.info(f"‚úÖ Extracted {df.height} records via streaming.")

        # 4. Tr·∫£ v·ªÅ LazyFrame v·ªõi x·ª≠ l√Ω Timezone chu·∫©n
        return (
            df.lazy()
            .with_columns(
                pl.from_epoch(pl.col("timestamp"), time_unit="ms")
                .alias("timestamp_utc")
            )
            .with_columns(
                pl.col("timestamp_utc")
                .dt.replace_time_zone("UTC")              # ƒê√°nh d·∫•u g·ªëc l√† UTC
                .dt.convert_time_zone("Asia/Ho_Chi_Minh") # Chuy·ªÉn sang gi·ªù VN
                .alias("timestamp")
            )
            .select(["timestamp", "sensor_id", "count"])
        )

    def _extract_timestamp_from_filename(self, filename: str) -> Optional[int]:
        try:
            return int(filename.split("_")[-1].replace('.txt', ''))
        except (IndexError, ValueError):
            return None

# --- TEST SCRIPT ƒê·ªÇ SO S√ÅNH ---
if __name__ == "__main__":
    import time
    import tracemalloc  # <--- Th∆∞ vi·ªán ƒëo b·ªô nh·ªõ
    
    # Path file (b·∫°n s·ª≠a l·∫°i cho ƒë√∫ng file ƒëang test)
    path = "hcmc-traffic-data.json"
    
    print("-" * 60)
    print(f"üöÄ Testing Extraction with MEMORY PROFILING")
    print(f"üìÅ File: {path}")
    print("-" * 60)

    try:
        # 1. B·∫Øt ƒë·∫ßu theo d√µi RAM
        tracemalloc.start()
        
        # 2. B·∫Øt ƒë·∫ßu b·∫•m gi·ªù
        start_time = time.time()
        
        # --- CH·∫†Y EXTRACTOR ---
        extractor = MinIoTrafficExtractor(path)
        # collect() l√† l√∫c data th·ª±c s·ª± ƒë∆∞·ª£c load v√†o RAM
        df = extractor.extract().collect() 
        # ----------------------

        # 3. K·∫øt th√∫c b·∫•m gi·ªù
        end_time = time.time()
        duration = end_time - start_time
        
        # 4. L·∫•y th√¥ng s·ªë RAM (current, peak)
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop() # D·ª´ng theo d√µi
        
        # Chuy·ªÉn ƒë·ªïi sang MB
        peak_mb = peak / 1024 / 1024
        
        # 5. In k·∫øt qu·∫£
        print("\n" + "=" * 60)
        print("‚úÖ EXTRACTION SUCCESSFUL")
        print("=" * 60)
        print(f"‚è±Ô∏è  Time taken:      {duration:.4f} seconds")
        print(f"üß† Peak RAM Usage:  {peak_mb:.2f} MB")  # <--- S·ª∞ KH√ÅC BI·ªÜT L√Ä ƒê√ÇY
        print(f"üìä Total Rows:      {df.height}")
        print("-" * 60)
        
    except Exception as e:
        print("\n‚ùå TEST FAILED")
        print(f"Error details: {e}")